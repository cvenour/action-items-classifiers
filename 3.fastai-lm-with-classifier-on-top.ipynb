{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's download the dataset we are going to study. The [dataset](http://ai.stanford.edu/~amaas/data/sentiment/) has been curated by Andrew Maas et al. and contains a total of 100,000 reviews on IMDB. 25,000 of them are labelled as positive and negative for training, another 25,000 are labelled for testing (in both cases they are highly polarized). The remaning 50,000 is an additional unlabelled data (but we will find a use for it nonetheless).\n",
    "\n",
    "We'll begin with a sample we've prepared for you, so that things run quickly before going over the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I have a file full of the training, development and test set data. Why one file containing all the data?\n",
    "#I'm going to use this data to fine-tune the wiki103 Language Model into a meetings Language model. I want\n",
    "#as much meeting text as I can get to fine-tune the LM and that's what this file is for.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#There are problems with the action items csv. I get UnicodeDecodeError: 'utf8' codec can't decode byte whatever in position whatever: invalid start byte\n",
    "#fastai course talks about this here: https://youtu.be/CJKnDu2dxOE?t=2414\n",
    "#You can avoid it when loading into a pandas dataframe by going\n",
    "#****************df = pd.read_csv(path, encoding='latin-1')*********************\n",
    "\n",
    "#But I'm not loading it directly into a pandas dataframe. So here's what I did:\n",
    "#Open up train_balanced_4.csv in Excel. The first column should be label\n",
    "#The second column should be text. Save as a tab delimited text file. This, I think,\n",
    "#gets rid of any weird encodings.\n",
    "#Then load up the tab delimited text file into Excel and then save as a csv.\n",
    "\n",
    "path = \"../action-items-data/data-originals/train-dev-test.csv\"\n",
    "f  = open(path,\"rb\")\n",
    "text = f.read().decode(errors='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('../action-items-data/data-for-fastai/train-dev-test2.csv', 'w')\n",
    "f.write(text)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>xxmaj ken can you hear me . xxbos xxmaj and try to figure out a way that we can bring summaries and action items to the forefront on the dashboard . xxbos i can move that up in the queue of what i 'm working on then . xxbos a month in , it 's like , xxmaj hey , there 's a project xxunk . xxbos 'cause , like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>and last thing , i 'm hoping to touch on that this afternoon is i got ta finish up my stuff here , just go through that site survey i did , make sure i have everything because i need to prepare to xxunk those xxup ip back out with xxunk series so we can send those 20 of those xxmaj xxunk back . xxbos been working daily at an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>to happen , right ? xxbos if we could just have a touch point with him on the setting up a lunch and learn or even having a conversation with him , that 'd be awesome . xxbos xxmaj we 'll work on trying to xxunk those and get those in the xxunk and the thing with xxmaj hendricks is the more you use it the better it gets ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>, so . xxbos i just xxunk an interesting problem that i then tried to create a new one and i then have xxunk something because the invoice that i usually use to create it is now responding with a , xxmaj hey . xxbos xxmaj that 's the xxunk of the way that we started to separate things . xxbos xxmaj so the interesting thing about this is we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>a community , right . xxbos xxmaj so we just xxunk off an eight week development cycle with xxup ibm 's blue xxunk xxunk team in xxmaj toronto , so i have four xxunk working on the project right now here locally . xxbos i need to talk to xxmaj paul before i work on the blog post . xxbos xxmaj then when he xxunk that he 's going to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now we can properly load into fastai object\n",
    "path = \"../action-items-data/data-for-fastai/\"\n",
    "#data_for_lm = TextClasDataBunch.from_csv(path, 'train-dev-test2.csv')\n",
    "data_for_lm = TextLMDataBunch.from_csv(path, 'train-dev-test2.csv')\n",
    "data_for_lm.show_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_for_lm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'fastai.text.data.TextLMDataBunch'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data_for_lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The texts have been tokenized. The tokenizer did more than just split on space and punctuation symbols: \n",
    "- the \"'s\" are grouped together in one token\n",
    "- the contractions are separated like this: \"did\", \"n't\"\n",
    "- content has been cleaned for any HTML symbol and lower cased\n",
    "- there are several special tokens (all those that begin by xx), to replace unknown tokens (see below) or to introduce different text fields (here we only have one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numericalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have extracted tokens from our texts, we convert to integers by creating a list of all the words used. We only keep the ones that appear at least twice with a maximum vocabulary size of 60,000 (by default) and replace the ones that don't make the cut by the unknown token `UNK`.\n",
    "\n",
    "The correspondance from ids to tokens is stored in the `vocab` attribute of our datasets, in a dictionary called `itos` (for int to string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxfld']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_lm.vocab.itos[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we look at what a what's in our datasets, we'll see the tokenized text as a representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos xxmaj let me know ."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_lm.train_ds[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the underlying data is all numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   5, 108,  67,  46,  10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_lm.train_ds[0][0].data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now let's do the same as above for the train-dev set. This dataset will be used to train the classifier\n",
    "path = \"../action-items-data/data-originals/train-dev.csv\"\n",
    "g  = open(path,\"rb\")\n",
    "text = g.read().decode(errors='replace')\n",
    "\n",
    "g = open('../action-items-data/data-for-fastai/train-dev2.csv', 'w')\n",
    "g.write(text)\n",
    "g.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj so , i was under the xxunk that , if we could work from that document and um , since you guys knew xxmaj xxunk and xxmaj havana xxmaj club , um , the best as far as like why they would , uh , you know , uh , potentially see value in something like this , especially around the the engagement that we were building around</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos i got ta go buy , go get , xxunk me , just go grab a box of cable and make that 35 foot cable for the tower , for xxunk and also four short xxunk xxunk for xxunk up 18 to extend those ones that do n't reach the patch panel , and once i got those xxunk in the patch panel i got ta get into netdoc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj so , but if you could do something quickly , to either xxunk that yeah , okay , it has the exact same problem that xxmaj watson has , and that it 's like , okay , double down on hopefully having xxup ibm figure it out , or if for some reason it does n't get xxunk down , then it 's like , you know ,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj yeah , so , i think , obviously , some of the good next steps here is , uh , xxmaj xxunk will xxunk that scope of work , um , i mean he had a really good idea when we were on the phone this past week in terms of what the xxunk are and - and just the - the executive summary and stuff , so</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj and the purpose of this meeting as we continue to develop and fine xxunk what will ultimately be the report on the 14th , and that 's in calendar , is that we want to take xxmaj if you look at the agenda today , , what we have in the agenda is , i do n't want to call it a laundry list , but i would</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now we can properly load into fastai object\n",
    "path = \"../action-items-data/data-for-fastai/\"\n",
    "\n",
    "data_for_classifier = (TextList.from_csv(path, 'train-dev2.csv', cols='text', vocab=data_for_lm.vocab)\n",
    "                .split_from_df(col=2)\n",
    "                .label_from_df(cols=0)\n",
    "                .databunch())\n",
    "\n",
    "\n",
    "data_for_classifier.show_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxfld']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_lm.vocab.itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_for_lm.save('data_for_language_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos xxmaj so what i want to check on this , is go back to the one 's that xxmaj xxunk 's having issues with , and see if you can xxunk the xxunk ."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_classifier.train_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   5,  21,  35,  13,  71,  12, 188,  24,  39])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_classifier.train_ds[0][0].data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos xxmaj and i did some updates on the slides ."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_classifier.valid_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    5,   14,   13,  134,   58, 1382,   24,   11,  998])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_classifier.valid_ds[0][0].data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_for_classifier.save('data_clas.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then put this in a learner object very easily with a model loaded with the pretrained weights. They'll be downloaded the first time you'll execute the following line and stored in `~/.fastai/models/` (or elsewhere if you specified different paths in your config file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_for_lm, AWD_LSTM, drop_mult=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:03 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.947279</td>\n",
       "      <td>4.531560</td>\n",
       "      <td>0.219048</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.save('fit_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.load('fit_head');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the fine-tuning, we can then unfeeze and launch a new training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:44 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.543481</td>\n",
       "      <td>4.257114</td>\n",
       "      <td>0.228943</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.285683</td>\n",
       "      <td>3.780717</td>\n",
       "      <td>0.272098</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.083746</td>\n",
       "      <td>3.679339</td>\n",
       "      <td>0.281622</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.927196</td>\n",
       "      <td>3.626594</td>\n",
       "      <td>0.287574</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.792123</td>\n",
       "      <td>3.595648</td>\n",
       "      <td>0.287574</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.666190</td>\n",
       "      <td>3.588443</td>\n",
       "      <td>0.287574</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.555601</td>\n",
       "      <td>3.574065</td>\n",
       "      <td>0.290848</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.451354</td>\n",
       "      <td>3.572628</td>\n",
       "      <td>0.288765</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.365528</td>\n",
       "      <td>3.570925</td>\n",
       "      <td>0.287426</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.296364</td>\n",
       "      <td>3.570274</td>\n",
       "      <td>0.287277</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.save('fine_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is our model? Well let's try to see what it predicts after a few given words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (1745 items)\n",
       "x: LMTextList\n",
       "xxbos xxmaj let me know .,xxbos xxmaj it 's going to be me sitting down with xxmaj paul to do a brief xxunk , and it 's going to be more on the product side rather than on xxmaj paul 's interest into the company .,xxbos xxmaj so it 's , that 's some of the activities that need to be xxunk on . i 'm hoping that you can um , you can take on .,xxbos xxmaj so for the action items , um , xxunk we 've xxunk like the person , like the , the clean utterance , and like the date that it 's due .,xxbos i am working with xxmaj xxunk on the help desk to run the xxunk , and the control test .\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Valid: LabelList (437 items)\n",
       "x: LMTextList\n",
       "xxbos xxmaj after that we 'll see just about xxunk our existing beta clients by converting them into xxunk , and then just xxunk more clients .,xxbos xxmaj in fact , you know , we can help you with them .,xxbos xxmaj and my team has to xxunk xxunk each one of them when sales xxunk them a request and says , xxmaj charge $ 20 to this customer .,xxbos xxmaj yeah , so , working on those updates ... xxmaj as i was xxunk xxmaj xxunk , i think i 'm gon na be ready for those for xxmaj monday , first thing xxunk,xxbos xxmaj given that the event is not until xxmaj november , if you wanted us to take a look at a draft in xxunk of that , we 'd be happy to come in and do that too and just let you know if you 're on track .\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(1695, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(1695, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=1695, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fa0a46fea60>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('../action-items-data/data-for-fastai'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True)], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (1745 items)\n",
       "x: LMTextList\n",
       "xxbos xxmaj let me know .,xxbos xxmaj it 's going to be me sitting down with xxmaj paul to do a brief xxunk , and it 's going to be more on the product side rather than on xxmaj paul 's interest into the company .,xxbos xxmaj so it 's , that 's some of the activities that need to be xxunk on . i 'm hoping that you can um , you can take on .,xxbos xxmaj so for the action items , um , xxunk we 've xxunk like the person , like the , the clean utterance , and like the date that it 's due .,xxbos i am working with xxmaj xxunk on the help desk to run the xxunk , and the control test .\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Valid: LabelList (437 items)\n",
       "x: LMTextList\n",
       "xxbos xxmaj after that we 'll see just about xxunk our existing beta clients by converting them into xxunk , and then just xxunk more clients .,xxbos xxmaj in fact , you know , we can help you with them .,xxbos xxmaj and my team has to xxunk xxunk each one of them when sales xxunk them a request and says , xxmaj charge $ 20 to this customer .,xxbos xxmaj yeah , so , working on those updates ... xxmaj as i was xxunk xxmaj xxunk , i think i 'm gon na be ready for those for xxmaj monday , first thing xxunk,xxbos xxmaj given that the event is not until xxmaj november , if you wanted us to take a look at a draft in xxunk of that , we 'd be happy to come in and do that too and just let you know if you 're on track .\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(1695, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(1695, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=1695, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fa0a46fea60>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('../action-items-data/data-for-fastai'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(1695, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(1695, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=1695, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(1695, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(1695, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=1695, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('fine_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suzanne met with the steering committee today .\n",
      "Suzanne met with the steering committee today ,\n",
      "Suzanne met with the steering committee today ,\n",
      "Suzanne met with the steering committee today ,\n",
      "Suzanne met with the steering committee today ,\n",
      "Suzanne met with the steering committee today and\n",
      "Suzanne met with the steering committee today and\n",
      "Suzanne met with the steering committee today ,\n",
      "Suzanne met with the steering committee today to\n",
      "Suzanne met with the steering committee today ,\n"
     ]
    }
   ],
   "source": [
    "#maybe do the following to get a bunch of predictions of what the next token might be\n",
    "TEXT = \"Suzanne met with the steering committee today\"\n",
    "print(\"\\n\".join(learn.predict(TEXT, 1, temperature=0.5) for _ in range(10)))\n",
    "#The cell below is better for this though i think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suzanne met with the steering committee today Xxunk met with the xxunk committee today and\n"
     ]
    }
   ],
   "source": [
    "#check this out: https://docs.fast.ai/text.learner.html#Get-predictions\n",
    "#Documentation says \"Lowering temperature will make the texts less randomized.\" Not sure what this means.\n",
    "#beam_search(text:str, n_words:int, no_unk:bool=True, top_k:int=10, beam_sz:int=1000, \n",
    "#temperature:float=1.0, sep:str=' ', decoder='decode_spec_tokens')\n",
    "\n",
    "answers = learn.beam_search(TEXT, 1, no_unk=True, top_k=10, beam_sz=1000, temperature=0.5)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suzanne met with the steering committee today Xxunk met with the xxunk committee today and\n",
      "Suzanne met with the steering committee today Xxunk met with the xxunk committee today .\n",
      "Suzanne met with the steering committee today Xxunk met with the xxunk committee today to\n",
      "Suzanne met with the steering committee today Xxunk met with the xxunk committee today and\n",
      "Suzanne met with the steering committee today Xxunk met with the xxunk committee today and\n",
      "Suzanne met with the steering committee today Xxunk met with the xxunk committee today and\n",
      "Suzanne met with the steering committee today Xxunk met with the xxunk committee today .\n",
      "Suzanne met with the steering committee today Xxunk met with the xxunk committee today ,\n",
      "Suzanne met with the steering committee today Xxunk met with the xxunk committee today ,\n",
      "Suzanne met with the steering committee today Xxunk met with the xxunk committee today .\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.beam_search(TEXT, 1, no_unk=True, top_k=10, beam_sz=1000, temperature=0.5) for _ in range(10)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We not only have to save the model, but also it's encoder, the part that's responsible for creating and updating the hidden state. For the next part, we don't care about the part that tries to guess the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.save_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a new data object that only grabs the labelled data and keeps those labels. Again, this line takes a bit of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that language models can use a lot of GPU, so you may need to decrease batchsize here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs=48\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"../action-items-data/data-for-fastai/\"\n",
    "data_clas = load_data(path, 'data_clas.pkl', bs=bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj so , i was under the xxunk that , if we could work from that document and um , since you guys knew xxmaj xxunk and xxmaj havana xxmaj club , um , the best as far as like why they would , uh , you know , uh , potentially see value in something like this , especially around the the engagement that we were building around</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj so , but if you could do something quickly , to either xxunk that yeah , okay , it has the exact same problem that xxmaj watson has , and that it 's like , okay , double down on hopefully having xxup ibm figure it out , or if for some reason it does n't get xxunk down , then it 's like , you know ,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj so that was kinda the original xxunk that we had with the company , and we 've been able to um use xxmaj xxunk as a as the foot in the door to talk with some other really interesting companies about providing them with quality uh xxunk design services , not just in xxmaj edmonton here , but we 're working with companies down in the xxmaj states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos i 'm gon na use it a little bit , obviously , i wanna help you out and push you to the xxunk who is gon na be attending the event , but maybe keep a little bit of an xxup ai xxunk on it then the other xxunk will see that it 's more of a xxunk and xxunk to their presentations rather than pitch for xxmaj hendricks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj so , that 's why we need to have the product xxunk agreed xxunk and seen by all the teams , because right now sales was xxunk last week that that particular service xxunk , even though their memory xxunk them , because we had that discussion about that service and it was decided that it 's not going to be used anymore .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a model to classify those reviews and load the encoder we saved before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder('fine_tuned_enc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:03 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.563474</td>\n",
       "      <td>0.483536</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.save('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.load('first');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:03 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.521980</td>\n",
       "      <td>0.416165</td>\n",
       "      <td>0.796667</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.save('second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.load('second');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:05 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.449083</td>\n",
       "      <td>0.389266</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.save('third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (1698 items)\n",
       "x: TextList\n",
       "xxbos xxmaj so what i want to check on this , is go back to the one 's that xxmaj xxunk 's having issues with , and see if you can xxunk the xxunk .,xxbos i think there 's just so much i can take away from you , and it 's just so xxunk for our xxunk to kind of be xxunk of these little takeaways .,xxbos been working daily at an old xxunk in a xxunk xxunk of the xxunk , so she .,xxbos i 'd say , if you 're still looking for the sponsorship and if it 's still .,xxbos xxmaj um , think xxmaj voice xxmaj xxunk was the only one that had xxunk five million before xxmaj february there , and then they got that 14 .\n",
       "y: CategoryList\n",
       "1,0,0,0,0\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Valid: LabelList (300 items)\n",
       "x: TextList\n",
       "xxbos xxmaj and i did some updates on the slides .,xxbos xxmaj make it relevant , make it relevant to xxmaj testfire . xxmaj like , how , think about , think when you think about um , the notes that you 're writing , how is it relevant to the organization and our audience ?,xxbos xxmaj yeah , it 's fantastic and it 's going to , i think , result in a much better product very soon .,xxbos xxmaj but , that would be a call that i 'd like to xxunk on .,xxbos xxmaj business cards should be xxunk at the xxunk xxmaj friday or xxmaj monday because i find orders are xxunk a business day or two faster , so expect those to arrive then .\n",
       "y: CategoryList\n",
       "0,1,0,1,1\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(1695, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(1695, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fa0a46fea60>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('../action-items-data/data-for-fastai'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (1698 items)\n",
       "x: TextList\n",
       "xxbos xxmaj so what i want to check on this , is go back to the one 's that xxmaj xxunk 's having issues with , and see if you can xxunk the xxunk .,xxbos i think there 's just so much i can take away from you , and it 's just so xxunk for our xxunk to kind of be xxunk of these little takeaways .,xxbos been working daily at an old xxunk in a xxunk xxunk of the xxunk , so she .,xxbos i 'd say , if you 're still looking for the sponsorship and if it 's still .,xxbos xxmaj um , think xxmaj voice xxmaj xxunk was the only one that had xxunk five million before xxmaj february there , and then they got that 14 .\n",
       "y: CategoryList\n",
       "1,0,0,0,0\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Valid: LabelList (300 items)\n",
       "x: TextList\n",
       "xxbos xxmaj and i did some updates on the slides .,xxbos xxmaj make it relevant , make it relevant to xxmaj testfire . xxmaj like , how , think about , think when you think about um , the notes that you 're writing , how is it relevant to the organization and our audience ?,xxbos xxmaj yeah , it 's fantastic and it 's going to , i think , result in a much better product very soon .,xxbos xxmaj but , that would be a call that i 'd like to xxunk on .,xxbos xxmaj business cards should be xxunk at the xxunk xxmaj friday or xxmaj monday because i find orders are xxunk a business day or two faster , so expect those to arrive then .\n",
       "y: CategoryList\n",
       "0,1,0,1,1\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(1695, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(1695, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fa0a46fea60>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('../action-items-data/data-for-fastai'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(1695, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(1695, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(1695, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(1695, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:14 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.417493</td>\n",
       "      <td>0.377853</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.402407</td>\n",
       "      <td>0.369867</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.save('action-item-classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (1698 items)\n",
       "x: TextList\n",
       "xxbos xxmaj so what i want to check on this , is go back to the one 's that xxmaj xxunk 's having issues with , and see if you can xxunk the xxunk .,xxbos i think there 's just so much i can take away from you , and it 's just so xxunk for our xxunk to kind of be xxunk of these little takeaways .,xxbos been working daily at an old xxunk in a xxunk xxunk of the xxunk , so she .,xxbos i 'd say , if you 're still looking for the sponsorship and if it 's still .,xxbos xxmaj um , think xxmaj voice xxmaj xxunk was the only one that had xxunk five million before xxmaj february there , and then they got that 14 .\n",
       "y: CategoryList\n",
       "1,0,0,0,0\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Valid: LabelList (300 items)\n",
       "x: TextList\n",
       "xxbos xxmaj and i did some updates on the slides .,xxbos xxmaj make it relevant , make it relevant to xxmaj testfire . xxmaj like , how , think about , think when you think about um , the notes that you 're writing , how is it relevant to the organization and our audience ?,xxbos xxmaj yeah , it 's fantastic and it 's going to , i think , result in a much better product very soon .,xxbos xxmaj but , that would be a call that i 'd like to xxunk on .,xxbos xxmaj business cards should be xxunk at the xxunk xxmaj friday or xxmaj monday because i find orders are xxunk a business day or two faster , so expect those to arrive then .\n",
       "y: CategoryList\n",
       "0,1,0,1,1\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(1695, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(1695, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fa0a46fea60>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('../action-items-data/data-for-fastai'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (1698 items)\n",
       "x: TextList\n",
       "xxbos xxmaj so what i want to check on this , is go back to the one 's that xxmaj xxunk 's having issues with , and see if you can xxunk the xxunk .,xxbos i think there 's just so much i can take away from you , and it 's just so xxunk for our xxunk to kind of be xxunk of these little takeaways .,xxbos been working daily at an old xxunk in a xxunk xxunk of the xxunk , so she .,xxbos i 'd say , if you 're still looking for the sponsorship and if it 's still .,xxbos xxmaj um , think xxmaj voice xxmaj xxunk was the only one that had xxunk five million before xxmaj february there , and then they got that 14 .\n",
       "y: CategoryList\n",
       "1,0,0,0,0\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Valid: LabelList (300 items)\n",
       "x: TextList\n",
       "xxbos xxmaj and i did some updates on the slides .,xxbos xxmaj make it relevant , make it relevant to xxmaj testfire . xxmaj like , how , think about , think when you think about um , the notes that you 're writing , how is it relevant to the organization and our audience ?,xxbos xxmaj yeah , it 's fantastic and it 's going to , i think , result in a much better product very soon .,xxbos xxmaj but , that would be a call that i 'd like to xxunk on .,xxbos xxmaj business cards should be xxunk at the xxunk xxmaj friday or xxmaj monday because i find orders are xxunk a business day or two faster , so expect those to arrive then .\n",
       "y: CategoryList\n",
       "0,1,0,1,1\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(1695, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(1695, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fa0a46fea60>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('../action-items-data/data-for-fastai'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(1695, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(1695, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(1695, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(1695, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('action-item-classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (1698 items)\n",
       "x: TextList\n",
       "xxbos xxmaj so what i want to check on this , is go back to the one 's that xxmaj xxunk 's having issues with , and see if you can xxunk the xxunk .,xxbos i think there 's just so much i can take away from you , and it 's just so xxunk for our xxunk to kind of be xxunk of these little takeaways .,xxbos been working daily at an old xxunk in a xxunk xxunk of the xxunk , so she .,xxbos i 'd say , if you 're still looking for the sponsorship and if it 's still .,xxbos xxmaj um , think xxmaj voice xxmaj xxunk was the only one that had xxunk five million before xxmaj february there , and then they got that 14 .\n",
       "y: CategoryList\n",
       "1,0,0,0,0\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Valid: LabelList (300 items)\n",
       "x: TextList\n",
       "xxbos xxmaj and i did some updates on the slides .,xxbos xxmaj make it relevant , make it relevant to xxmaj testfire . xxmaj like , how , think about , think when you think about um , the notes that you 're writing , how is it relevant to the organization and our audience ?,xxbos xxmaj yeah , it 's fantastic and it 's going to , i think , result in a much better product very soon .,xxbos xxmaj but , that would be a call that i 'd like to xxunk on .,xxbos xxmaj business cards should be xxunk at the xxunk xxmaj friday or xxmaj monday because i find orders are xxunk a business day or two faster , so expect those to arrive then .\n",
       "y: CategoryList\n",
       "0,1,0,1,1\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(1695, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(1695, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fa0a46fea60>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('../action-items-data/data-for-fastai'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (1698 items)\n",
       "x: TextList\n",
       "xxbos xxmaj so what i want to check on this , is go back to the one 's that xxmaj xxunk 's having issues with , and see if you can xxunk the xxunk .,xxbos i think there 's just so much i can take away from you , and it 's just so xxunk for our xxunk to kind of be xxunk of these little takeaways .,xxbos been working daily at an old xxunk in a xxunk xxunk of the xxunk , so she .,xxbos i 'd say , if you 're still looking for the sponsorship and if it 's still .,xxbos xxmaj um , think xxmaj voice xxmaj xxunk was the only one that had xxunk five million before xxmaj february there , and then they got that 14 .\n",
       "y: CategoryList\n",
       "1,0,0,0,0\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Valid: LabelList (300 items)\n",
       "x: TextList\n",
       "xxbos xxmaj and i did some updates on the slides .,xxbos xxmaj make it relevant , make it relevant to xxmaj testfire . xxmaj like , how , think about , think when you think about um , the notes that you 're writing , how is it relevant to the organization and our audience ?,xxbos xxmaj yeah , it 's fantastic and it 's going to , i think , result in a much better product very soon .,xxbos xxmaj but , that would be a call that i 'd like to xxunk on .,xxbos xxmaj business cards should be xxunk at the xxunk xxmaj friday or xxmaj monday because i find orders are xxunk a business day or two faster , so expect those to arrive then .\n",
       "y: CategoryList\n",
       "0,1,0,1,1\n",
       "Path: ../action-items-data/data-for-fastai;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(1695, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(1695, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fa0a46fea60>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('../action-items-data/data-for-fastai'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(1695, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(1695, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(1695, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(1695, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn2 = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
    "learn2.load('action-item-classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.0070, 0.9930]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn2.predict(\"I'll get that to you as soon as I've finished it.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.0065, 0.9935]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"I'll get that to you as soon as I've finished it.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.6481, 0.3519]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"I think we did a little presentation at the end.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.8464, 0.1536]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"Okay, yeah that'd be great. And, I think like, I think where we need like the biggest muscle is um, you know um navigating . You know, especially like the provincial and federal um, opportunities and stuff, and what not. Um.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.0081, 0.9919]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"I'll give him a call later on today.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python fastai2019b",
   "language": "python",
   "name": "fastai2019b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
